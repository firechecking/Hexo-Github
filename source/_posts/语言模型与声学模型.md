---
title: 语言模型与声学模型
date: 2017-02-17 16:11:19
tags: [机器学习,语音识别]
categories: [机器学习,语音识别]
comments: true
---
# 参考链接
<https://www.zhihu.com/question/35833334>
<http://blog.csdn.net/by21010/article/details/51506292>
<http://blog.csdn.net/zjm750617105/article/details/51785526><!--more-->
# 语言识别简介
语音识别系统的目的，是把语音转换成文字。具体来说，是输入一段语音信号，要找一个文字序列（由词或字组成），使得它与语音信号的匹配程度最高。这个匹配程度，一般是用概率表示的。用X表示语音信号，W表示文字序列，则要求解的是下面这个问题：

$$W^*=arg\max_WP(W|X)$$

使用贝叶斯公式，可以把条件和结论反过来：

$$W^*=arg\max_W \frac{P(X|W)P(W)}{P(X)}= arg\max_WP(X|W)P(W)$$

第二步省略分母是因为我们要优化的是W，而P(X)不含W，是常数。

这就是语音识别里`最核心的公式`。可以这样形象地理解它：我们要找的W，需要使得P(W)和P(X|W)都大。P(W)表示一个文字序列本身的概率，也就是这一串词或字本身有多“像话”；P(X|W)表示给定文字后语音信号的概率，即这句话有多大的可能发成这串音。计算这两项的值，就是`语言模型`和`声学模型`各自的任务。

声学模型就是把语音的声学特征(MFCC)分类对应到（解码）音素或字词这样的单元。语言模型接着把字词解码成一个完整的句子

# 语言模型(language model)
1. N-Gram模型

	N-Gram是大词汇连续语音识别中常用的一种语言模型，对中文而言，我们称之为汉语语言模型(CLM, Chinese Language Model)。汉语语言模型利用上下文中相邻词间的搭配信息，在需要把连续无空格的拼音、笔划，或代表字母或笔划的数字，转换成汉字串(即句子)时，可以计算出具有最大概率的句子，从而实现到汉字的自动转换，无需用户手动选择，避开了许多汉字对应一个相同的拼音(或笔划串，或数字串)的重码问题。
	
	N-Gram基于这样一种假设，第n个词的出现只与前面N-1个词相关，而与其它任何词都不相关，整句的概率就是各个词出现概率的乘积。这些概率可以通过直接从语料中统计N个词同时出现的次数得到。常用的是二元的Bi-Gram和三元的Tri-Gram。
	
	对于一个句子T假设T是由词序列W1,W2,W3,…Wn组成的，那么:
	$$P(T)=P(W1W2W3Wn)=P(W1)P(W2|W1)P(W3|W1W2)…P(Wn|W1W2…Wn-1)$$
	  
	这种方法存在两个致命的缺陷：一个缺陷是参数空间过大，不可能实用化；另外一个缺陷是数据稀疏严重。
	
	为了解决这个问题，引入了马尔科夫假设：一个词的出现仅仅依赖于它前面出现的有限的一个或者几个词。
	
	如果一个词的出现仅依赖于它前面出现的一个词，那么我们就称之为bi-gram。即
  $$P(T)=P(W1)P(W2|W1)P(W3|W2)...P(Wn|Wn-1)$$
  
	如果一个词的出现仅依赖于它前面出现的两个词，那么我们就称之为tri-gram。即
	$$P(T) = P(W1)P(W2|W1)P(W3|W1W2)…P(Wn|Wn-2Wn-1)$$
	
	那么怎么得到P(Wn|W1W2…Wn-1)呢？一种简单的估计方法就是最大似然估计(Maximum Likelihood Estimate）了。即
	$$P(Wn|W1W2…Wn-1) = \frac{C(W1 W2…Wn)}{C(W1 W2…Wn-1)}$$

	剩下的工作就是在训练语料库中数数儿了，即统计序列C(W1 W2…Wn) 出现的次数和C(W1 W2…Wn-1)出现的次数。

	`针对N-Gram数据稀疏问题，要进行数据平滑（data Smoothing）`，数据平滑的目的有两个：一个是使所有的N-gram概率之和为1，使所有的N-gram概率都不为0.

# 声学模型(acoustic model)
声学模型的任务是计算P(X|W)

首先第一个问题就是：怎么才能知道每个单词应该发什么音呢？这就需要另一个模块，叫作词典（lexicon），它的作用就是把单词串转换成音素串。词典一般认为是跟声学模型、语言模型并列的模块。

有了词典的帮助，声学模型就知道给定的文字串该依次发哪些音了。不过，为了计算语音与音素串的匹配程度，还需要知道每个音素的起止时间。

这是通过动态规划算法来进行的，利用动态规则算法，可以高效地找到音素的分界点，使得每一段语音与音素的匹配程度（用概率表示）之积最大。实际使用的算法称为Viterbi算法，它不仅仅考虑了每一段语音与音素的匹配程度，还考虑了在各个音素之间转换的概率；后者是通过隐马尔可夫模型（HMM）估计出来的。
（实际系统中使用的是比音素更小的单位，不过原理是一样的）

在求音素分界点的过程中，以及在有了分界点后计算时，声学模型都需要知道怎样计算一个音素与一段语音信号的匹配程度。要做这件事，需要找到一种合适的表示语音信号的方法。一般是把语音信号分成许多帧，对于每一帧，通过傅里叶变换等一系列操作，把它转换成一个特征向量。最常用的特征是MFCC，具体提取过程可以参见语音识别技术中提取的声音特征的参数具体指什么？ - 频谱分析。从训练数据中，我们可以提取出大量的特征向量，以及它们对应的音素；利用这些数据，就可以训练从特征到音素的分类器。前些年最常用的分类器是高斯混合模型（GMM），它的大致原理是估计出每个音素的特征向量的分布，然后在识别阶段，计算每一帧的特征向量$x_t$由相应音素$s_i$产生的概率$P(x_t|s_i)$，把每一帧的概率相乘，就得到$P(X|W)$。现在，神经网络渐渐火了起来，它可以直接给出$P(s_i|x_t)$，用贝叶斯公式可以转换成，再相乘得到。
